딥러닝의 작동 순서

1. 임의의 값으로 예측을 시작해
2. 실제 값과 얼마나 차이가 있는지 측정해.
3. 손실을 통해 가중치를 변경해.

여기서 3 번의 과정이 가장 어려운데, 이 3번 과정을 하기 위해 경사하강법을 사용해.

간단하게는 랜덤 x 로 y 값을 얻어, 그 위치에서 x-y' 한 값으로 다시 계산하고 반복하는 거야.

추가적으로 여기에 x-lr*y' 처럼 학습률을 곱해줘서 사용해.

이것은 완전 정확한 극소값을 얻진 못해도, 한가지를 보장해. 바로 경사가 낮아지는 곳으로 이동한다는 거지.

---

그러나 만약 이미 극값에 있다면? 움직이지 않을 것이고, 극소값이 최소값이 아닐 경우도 있어.

그런데 이것이 의미가 있는 이유는 ,딥러닝은 아주 높은 차원의 수를 다뤄.

그래서 그 모든 차원에서 극소값은 매우매우 적을 거라는 거지. 어쩌면 없을 수도 있어.

정리하자면, 이런 경사하강법을 했을 때 좋은 퍼포먼스가 나오지 않는다면 해결방법은

- 처음을 여러번 반복해서 다양한 가중치로 시작을 하는거야.
- 아니면 차원을 더 복잡하게 만들어서. 극소값을 줄여 거의 수렴하지 않도록 하는 거야.

---

경사하강법에서,

기울기가 0인 수준에서 멈춘다면 수렴하지 않는 경우 무한루프에 빠질 수 있어.

그래서 2가지 조건으로 종료하는 것이 가장 이상적이야. 기울기가 한계점 이하인지 아니면 epoch를 다 돌았는지.


 
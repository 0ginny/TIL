{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqzRzWNRsOYXm2nHs2sA4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0ginny/TIL/blob/main/240402_About_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About CNN"
      ],
      "metadata": {
        "id": "ITqANZfTEFNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what are ConvolutionalNeural Networks?"
      ],
      "metadata": {
        "id": "bzQxniudEdMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 딥러닝은 착시와 같아\n",
        "    - 내가 분류하는 특징이 많은 곳을 보고 판단하지\n",
        "    - 그리고 확률적으로 알려줘.\n",
        "- 요즘 CNN이 많이 쓰여 ANN 보다도\n",
        "    - 이미지 처리에 쓰여서 그런가?\n",
        "        - 이미지를 간단히 만들거야.\n",
        "\n",
        "- CNN 은 이미지를 학습해서 출력을 내는 인공지능 기법\n",
        "- 그런데 보통 채색이나 흑백으로 판단이 아니라 2차원의 0과 1로 판단하나봐\n",
        "- 그래서 간단히 만들어주는 과정이 필요한가봐\n",
        "- 알고리즘 진행단계\n",
        "    1. convolution\n",
        "    2. Max Pooling\n",
        "    3. Flattening\n",
        "    4. Full Connection"
      ],
      "metadata": {
        "id": "1Wnwa1ZJFvns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nDfg_O3jQAPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 1. Convolution Operation"
      ],
      "metadata": {
        "id": "SjRDLTbGEdPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CNN Assay and Tutorior_Mathmatical_basic](https://cs.nju.edu.cn/wujx/index.htm)\n",
        "\n",
        "- 수학 공식\n",
        "<center>\n",
        "<img src = 'https://drive.google.com/uc?id=1cJI5P_esv6Fs8AIeuoJYgVora89z6df1' height = 200 width = 800>\n",
        "<center>"
      ],
      "metadata": {
        "id": "1Wu-PpSCIgqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 컨볼루션이란 이미지를 감는거? 줄이는 것?\n",
        "    - 여러 feature delector (fillter) (보통 3x3) 를 거쳐서 feature map을 만들어\n",
        "    - 각각 feature map 들은 이미지의 다른 특징을 가진 특징 데이터가 될거야.\n",
        "    - 그런 특징들을 통해 컴퓨터가 이미지를 판단할 수 있게 해주는 거지\n",
        "- 이미지를 줄이게 되니까. 더 빠른 연산을 할 수 있어.\n",
        "- 특징데이터를 남기니까 이미지가 줄어도 판단할 수 있어.\n",
        "\n",
        "<center>\n",
        "<img src = 'https://drive.google.com/uc?id=1y9yfD8iCV7pHIAM0Eka4qBfhA4MX6rMl' height = 350 width = 800>\n",
        "<center>"
      ],
      "metadata": {
        "id": "k5HnztqZNR9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 1(b) - ReLU Layer"
      ],
      "metadata": {
        "id": "z1B4PBP2EdRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [이 함수의 좋은점은 수학적으로 이해를 해야해](https://arxiv.org/pdf/1609.04112.pdf)\n",
        "    - 왜  ReLU 함수를 Convolution 할 때마다 적용시켜야 하나?\n",
        "    - [추가적인 ReLU함수에 대해서](https://arxiv.org/pdf/1502.01852.pdf)\n",
        "    - [한국어로 된 설명](https://dalsacoo-log.tistory.com/entry/what-is-CNN)\n",
        "    - [한국어로 된 자세한 설명](https://bcho.tistory.com/1149?category=555440)\n",
        "        - Sigmoid 같은 활성화 함수를 사용하면 Layer가 깊어질 경우 역전파가 잘 안 될 수 있대.\n",
        "- 하지만 간단히 설명하자면\n",
        "    - 점진적인 변화를 없애고, 급진적인 그니까 0과 1인 변화만 남겨줘.\n",
        "    - 선형성을 없애고 비선형적으로 표현해줘."
      ],
      "metadata": {
        "id": "U3q6m91WOUoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 2. Pooling"
      ],
      "metadata": {
        "id": "g7cWeiKpEdTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지의 형태가 회전이든, 옆면이든, 세로로 늘려있든 어떤 상황에서도 분류 가능해야해.\n",
        "- 그러기 위해 풀링을 써\n",
        "- 풀링의 장점\n",
        "    - 특징을 보존하고\n",
        "    - 공간적 불변성을 부여해 ( 즉 이미지가 변형되도 특징은 바뀌지 않아 )\n",
        "    - 데이터 용량도 줄어들지\n",
        "    - 매개변수를 줄여 -> 과적합을 막을 수도 있지.\n",
        "- 풀링 작동방식\n",
        "    - 2X2 같이 어느정도 크기로 잘라서 그 부분의 특징값만 저장해\n",
        "        - Max\n",
        "        - mean (sub sampling)\n",
        "        - sum 등등\n",
        "\n",
        "[풀링에 대한 쉬운 논문](https://www.ais.uni-bonn.de/papers/icann2010_maxpool.pdf)"
      ],
      "metadata": {
        "id": "C5Ze7bwCE_dW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 3 - Flattening"
      ],
      "metadata": {
        "id": "XFA5N-fzE2Zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2d Visualization](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)"
      ],
      "metadata": {
        "id": "lcEmFLBlhqiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 4. Full Connection\n"
      ],
      "metadata": {
        "id": "D1RyioRIE2nG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ANN과 동일하게 순전파 후 역전파로 가중치를 정해\n",
        "- 마지막 전 레이어에서는 각각 투표(?)를 할 수 있고\n",
        "- 출력레이어는 각각 어떤 뉴런들이 나한테 의미가 있고 어떤 뉴런은 의미가 없는지도 학습을 해. 그래서 어떤 것들은 무시할 거야. (특징감지기)\n",
        "\n",
        "[9CNN model](https://adeshpande3.github.io/)"
      ],
      "metadata": {
        "id": "vcIiiyJ5mHtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- softmax function\n",
        "    - 값들을 0과 1사이에있는 수로 만들어\n",
        "    - 총 합이 1이 되도록\n",
        "    - 그 분류된 값을 각 차원노드에 대입\n",
        "\n",
        "-크로스 엔트로피 함수\n",
        "    - 정확도를 더 잘 알 수 있어\n",
        "    - cross-entropy > MSE > Classificaiton Error\n",
        "    - 심지어 매우 쉬눙ㄴ 방법이야.\n",
        "    - RMS보다 좋은 장점\n",
        "        - 역전파 마지막 단계에서 값이 매우 작은 거야.\n",
        "        그럴 때 로그가 있어서 그러한 작은 차이도 구분할 수 있어.\n",
        "    - 대신 분류할 때만 더 좋은 방법이야.\n",
        "\n",
        "[크로스 엔트로피 개론](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)\n",
        "\n",
        "\n",
        "[수학적 배경](https://peterroelants.github.io/posts/cross-entropy-softmax/)"
      ],
      "metadata": {
        "id": "2IPHh4wpsGsw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5WsiJ1osFnj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
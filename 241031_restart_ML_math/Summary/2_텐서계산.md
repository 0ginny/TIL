# Tensor caculation

## Tenson Transposition

- 스칼라의 경우 동일
- 행렬의 경우, 열과 행을 바꿔줘.
- 명확하게는, 중심 선을 기준으로 대칭이동 하는 거야

```python
# X_np.T
# tf.transpose(X_tf)
# X_pt.T
```

## Basic Tensor calculation

- 텐서에서 덧셈과 곱셈은 기본적으로 모든 요소에 행해져
- 사실은 그냥 계산하면 연산에 과부하가 와서 아래의 함수를 쓰는 것이 좋아
  - torch.add(), torch.mul()
  - tf.add(),tf.multiply()

### 아다마르 곱, Hadamard product ( 행렬 곱이 아님 )

- A ⊙ B
- 텐서의 차원이 같을 경우, 요소끼리 연산이 가능
- np, torch, tf 에서 단순 텐서끼리 연산을 하면 아다마르 곱이 되어버려


## Reduction

- 텐서의 차원이 감소하는 것
- sum, maximum, minimum, mean, product 등 사용 가능

### sum

- 각 요소를 모두 더함
- X.sum()
  - (axis = 1) 로 덧셈할 차원을 선택할 수 있어
- torch.sum(X_pt)
  - (X_pt,1)
- tf.reduce_sum(X_tf)
  - (x_tf,1)

## Dot Product

- 표기볍
  - x · y
  - x<sup>T</sup>y
  - <x, y>
- 계산
  - np.dot(x,y)
  - torch.dot(x_pt,y_pt)
  - tf.reduce_sum(tf.multiply(x_tf, y_tf)) 차원이 같을 경우만
    - 차원이 다르면 tf.tensordot 사용